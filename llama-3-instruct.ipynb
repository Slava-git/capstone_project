{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":6703755,"sourceType":"datasetVersion","datasetId":3863727},{"sourceId":33551,"sourceType":"modelInstanceVersion","modelInstanceId":28083}],"dockerImageVersionId":30734,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libs ","metadata":{}},{"cell_type":"code","source":"# Install libs\n!pip install -qq peft==0.6.0\n!pip install -qq bitsandbytes==0.41.1\n!pip install -qq accelerate==0.24.1\n!pip install -qq transformers==4.35.0\n!pip install -qq torch~=2.1.0 --index-url https://download.pytorch.org/whl/cpu -q \n!pip install -qq torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html -q\n!pip uninstall -qq tensorflow -y\n!cp /kaggle/input/utils-xla/spmd_util.py ","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:50:30.226101Z","iopub.execute_input":"2024-07-03T20:50:30.226442Z","iopub.status.idle":"2024-07-03T20:52:27.409208Z","shell.execute_reply.started":"2024-07-03T20:50:30.226414Z","shell.execute_reply":"2024-07-03T20:52:27.408157Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndiffusers 0.28.0 requires huggingface-hub>=0.20.2, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchvision 0.18.0 requires torch==2.3.0, but you have torch 2.1.2+cpu which is incompatible.\ntorchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.2+cpu which is incompatible.\ntorchaudio 2.3.0 requires torch==2.3.0, but you have torch 2.1.2+cpu which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nfrom time import time\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\nimport torch\nimport transformers\nfrom sklearn.metrics import accuracy_score\nfrom transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification\nfrom peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\nimport torch.nn.functional as F\n\nimport torch_xla.debug.profiler as xp\nimport torch_xla.core.xla_model as xm\nimport torch_xla.experimental.xla_sharding as xs\nimport torch_xla.runtime as xr\n\nxr.use_spmd()\n\nfrom torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor\nfrom torch_xla.experimental.xla_sharding import Mesh\nfrom spmd_util import partition_module\n\ntqdm.pandas()\n\nprint(f'Torch Version: {torch.__version__}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:52:27.410964Z","iopub.execute_input":"2024-07-03T20:52:27.411254Z","iopub.status.idle":"2024-07-03T20:52:43.852839Z","shell.execute_reply.started":"2024-07-03T20:52:27.411224Z","shell.execute_reply":"2024-07-03T20:52:43.851848Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/usr/local/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n","output_type":"stream"},{"name":"stdout","text":"/usr/local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\nTorch Version: 2.1.2+cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"class CFG:\n    NUM_EPOCHS = 2\n    BATCH_SIZE = 8\n    DROPOUT = 0.05 \n    MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n    SEED = 2024 \n    MAX_LENGTH = 1080 \n    NUM_WARMUP_STEPS = 128\n    LR_MAX = 5e-5 \n    NUM_LABELS = 3 \n    LORA_RANK = 4\n    LORA_ALPHA = 8\n    LORA_MODULES = ['o_proj', 'v_proj']\n    \nDEVICE = xm.xla_device() # Initialize TPU Device","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:22.238558Z","iopub.execute_input":"2024-07-03T20:53:22.239755Z","iopub.status.idle":"2024-07-03T20:53:22.244794Z","shell.execute_reply.started":"2024-07-03T20:53:22.239712Z","shell.execute_reply":"2024-07-03T20:53:22.243907Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def set_seeds(seed):\n    \"\"\"Set seeds for reproducibility \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        \n    # Set seed for all TPU cores\n    xm.set_rng_state(seed, device=xm.xla_device())  \n\nset_seeds(seed=CFG.SEED)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:24.282234Z","iopub.execute_input":"2024-07-03T20:53:24.283172Z","iopub.status.idle":"2024-07-03T20:53:24.289325Z","shell.execute_reply.started":"2024-07-03T20:53:24.283136Z","shell.execute_reply":"2024-07-03T20:53:24.288559Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_NAME)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = 'right'\ntokenizer.add_eos_token = True\n\n# save tokenizer to load offline during inference\ntokenizer.save_pretrained('tokenizer')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:26.940166Z","iopub.execute_input":"2024-07-03T20:53:26.940533Z","iopub.status.idle":"2024-07-03T20:53:27.603785Z","shell.execute_reply.started":"2024-07-03T20:53:26.940503Z","shell.execute_reply":"2024-07-03T20:53:27.603052Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Utility function giving token length\ndef get_token_lengths(texts):\n    # tokenize and receive input_ids for reach text\n    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n    # return length of inputs_ids for each text\n    return [len(t) for t in input_ids]","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:27.605185Z","iopub.execute_input":"2024-07-03T20:53:27.605490Z","iopub.status.idle":"2024-07-03T20:53:27.609841Z","shell.execute_reply.started":"2024-07-03T20:53:27.605461Z","shell.execute_reply":"2024-07-03T20:53:27.609163Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Prepare train\n","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\ndef process(input_str):\n    stripped_str = input_str.strip('[]')\n    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n    return  ' '.join(sentences)\n\ntrain.loc[:, 'prompt'] = train['prompt'].apply(process)\ntrain.loc[:, 'response_a'] = train['response_a'].apply(process)\ntrain.loc[:, 'response_b'] = train['response_b'].apply(process)\n\n# Drop 'Null' for training\nindexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\ntrain.drop(indexes, inplace=True)\ntrain.reset_index(inplace=True, drop=True)\n\nprint(f\"Total {len(indexes)} Null response rows dropped\")\nprint('Total train samples: ', len(train))","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:33.177839Z","iopub.execute_input":"2024-07-03T20:53:33.178160Z","iopub.status.idle":"2024-07-03T20:53:36.939301Z","shell.execute_reply.started":"2024-07-03T20:53:33.178132Z","shell.execute_reply":"2024-07-03T20:53:36.938571Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total 19 Null response rows dropped\nTotal train samples:  57458\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T14:47:20.90852Z","iopub.execute_input":"2024-06-14T14:47:20.908785Z","iopub.status.idle":"2024-06-14T14:47:20.921893Z","shell.execute_reply.started":"2024-06-14T14:47:20.90876Z","shell.execute_reply":"2024-06-14T14:47:20.921234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\nprint(train['text'][4])","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:36.940510Z","iopub.execute_input":"2024-07-03T20:53:36.940753Z","iopub.status.idle":"2024-07-03T20:53:37.249234Z","shell.execute_reply.started":"2024-07-03T20:53:36.940728Z","shell.execute_reply":"2024-07-03T20:53:37.248572Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"User prompt: What is the best way to travel from Tel-Aviv to Jerusalem? Car? Bus? Plane?\n\nModel A :\nThe best way to travel from Tel Aviv to Jerusalem depends on your personal preference and the availability of transportation options. All the options you have mentioned are valid options, but here are some details to help you make your decision:\\n\\n*   By car: Traveling by car is the quickest way to get from Tel Aviv to Jerusalem, as the distance between the two cities is only about 60 kilometers (37 miles). It takes around 45 minutes to drive from Tel Aviv to Jerusalem by car, depending on the traffic.\\n*   By bus: There are several bus lines that run from Tel Aviv to Jerusalem, and the journey takes around 1 hour and 30 minutes by bus. The buses are comfortable and reliable, and they offer a scenic view of the beautiful Israeli countryside.\\n*   By plane: There are no direct flights from Tel Aviv to Jerusalem, so you need to take a flight from Tel Aviv's Ben Gurion International Airport to Jerusalem's Sde Dov Airport. The flight takes around 30 minutes, and it is a convenient option if you are short on time.\\n\\nIn general, if you have enough time and don't mind taking the bus, I recommend that option. The buses are comfortable, reliable, and offer a scenic view of the countryside. If you are short on time and don't want to take a bus, a flight is another option to consider.\n\n--------\n\nModel B:\nThe best way to travel from Tel-Aviv to Jerusalem depends on your personal preferences and circumstances. \\n\\nIf you have a car and enjoy driving, then driving from Tel-Aviv to Jerusalem is an option. However, parking in Jerusalem can be challenging and expensive.\\n\\nIf you prefer to use public transportation, there are several bus lines that operate between Tel-Aviv and Jerusalem. Some of the most popular bus companies include Egged and Dan. The bus ride typically takes about an hour, depending on traffic.\\n\\nTaking a plane is not a recommended option since Tel-Aviv and Jerusalem are relatively close cities, and there are no airports in Jerusalem. \\n\\nIn summary, taking a bus is the most commonly used and convenient way to travel from Tel-Aviv to Jerusalem.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train with only take 50% train dataset\ntrain = train[:int(len(train) * 0.5)]\n\ntrain.loc[:, 'token_count'] = get_token_lengths(train['text'])\n\n# prepare label for model\ntrain.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)\n\n# Display data\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:38.585932Z","iopub.execute_input":"2024-07-03T20:53:38.586510Z","iopub.status.idle":"2024-07-03T20:53:57.617556Z","shell.execute_reply.started":"2024-07-03T20:53:38.586474Z","shell.execute_reply":"2024-07-03T20:53:57.616695Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  Is it morally right to try to have a certain p...   \n1  What is the difference between marriage licens...   \n2  explain function calling. how would you call a...   \n3  How can I create a test set for a very rare ca...   \n4  What is the best way to travel from Tel-Aviv t...   \n\n                                          response_a  \\\n0  The question of whether it is morally right to...   \n1  A marriage license is a legal document that al...   \n2  Function calling is the process of invoking or...   \n3  Creating a test set for a very rare category c...   \n4  The best way to travel from Tel Aviv to Jerusa...   \n\n                                          response_b  winner_model_a  \\\n0  As an AI, I don't have personal beliefs or opi...               1   \n1  A marriage license and a marriage certificate ...               0   \n2  Function calling is the process of invoking a ...               0   \n3  When building a classifier for a very rare cat...               1   \n4  The best way to travel from Tel-Aviv to Jerusa...               0   \n\n   winner_model_b  winner_tie  \\\n0               0           0   \n1               1           0   \n2               0           1   \n3               0           0   \n4               1           0   \n\n                                                text  token_count  label  \n0  User prompt: Is it morally right to try to hav...         1205      0  \n1  User prompt: What is the difference between ma...         1392      1  \n2  User prompt: explain function calling. how wou...          663      2  \n3  User prompt: How can I create a test set for a...         1007      0  \n4  User prompt: What is the best way to travel fr...          478      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n      <th>text</th>\n      <th>token_count</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>Is it morally right to try to have a certain p...</td>\n      <td>The question of whether it is morally right to...</td>\n      <td>As an AI, I don't have personal beliefs or opi...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>User prompt: Is it morally right to try to hav...</td>\n      <td>1205</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>What is the difference between marriage licens...</td>\n      <td>A marriage license is a legal document that al...</td>\n      <td>A marriage license and a marriage certificate ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>User prompt: What is the difference between ma...</td>\n      <td>1392</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>explain function calling. how would you call a...</td>\n      <td>Function calling is the process of invoking or...</td>\n      <td>Function calling is the process of invoking a ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>User prompt: explain function calling. how wou...</td>\n      <td>663</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>How can I create a test set for a very rare ca...</td>\n      <td>Creating a test set for a very rare category c...</td>\n      <td>When building a classifier for a very rare cat...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>User prompt: How can I create a test set for a...</td>\n      <td>1007</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>What is the best way to travel from Tel-Aviv t...</td>\n      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>User prompt: What is the best way to travel fr...</td>\n      <td>478</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# token Count\ndisplay(train['token_count'].describe().to_frame().astype(int))","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:57.619020Z","iopub.execute_input":"2024-07-03T20:53:57.619352Z","iopub.status.idle":"2024-07-03T20:53:57.630437Z","shell.execute_reply.started":"2024-07-03T20:53:57.619322Z","shell.execute_reply":"2024-07-03T20:53:57.629636Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"       token_count\ncount        28729\nmean           728\nstd            768\nmin             17\n25%            287\n50%            562\n75%            899\nmax          15427","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>28729</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>728</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>768</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>287</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>562</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>899</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15427</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['token_count'].hist()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:54:10.033741Z","iopub.execute_input":"2024-07-03T20:54:10.034075Z","iopub.status.idle":"2024-07-03T20:54:10.222490Z","shell.execute_reply.started":"2024-07-03T20:54:10.034047Z","shell.execute_reply":"2024-07-03T20:54:10.221819Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<Axes: >"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# get length of tokens which covers 90% of data, we'll still take 1024 length!\nnp.percentile(train['token_count'], 90)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:53:57.631342Z","iopub.execute_input":"2024-07-03T20:53:57.631603Z","iopub.status.idle":"2024-07-03T20:53:57.646618Z","shell.execute_reply.started":"2024-07-03T20:53:57.631576Z","shell.execute_reply":"2024-07-03T20:53:57.645663Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"1398.2000000000007"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenize","metadata":{}},{"cell_type":"code","source":"# Tokenize Data\ntokens = tokenizer(\n    train['text'].tolist(), \n    padding='max_length', \n    max_length=CFG.MAX_LENGTH, \n    truncation=True, \n    return_tensors='np')\n\n# Input IDs are the token IDs\nINPUT_IDS = tokens['input_ids']\n# Attention Masks to Ignore Padding Tokens\nATTENTION_MASKS = tokens['attention_mask']\n# Label of Texts\nLABELS = train[['winner_model_a','winner_model_b','winner_tie']].values\n\nprint(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')\nprint(f'LABELS shape: {LABELS.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:54:25.989416Z","iopub.execute_input":"2024-07-03T20:54:25.989787Z","iopub.status.idle":"2024-07-03T20:54:43.698433Z","shell.execute_reply.started":"2024-07-03T20:54:25.989756Z","shell.execute_reply":"2024-07-03T20:54:43.697685Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"INPUT_IDS shape: (28729, 1080), ATTENTION_MASKS shape: (28729, 1080)\nLABELS shape: (28729, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_dataset(batch_size):\n    N_SAMPLES = LABELS.shape[0]\n    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))\n    while True:\n        # Shuffle Indices\n        np.random.shuffle(IDXS)\n        # Iterate Over All Indices Once\n        for idxs in IDXS.reshape(-1, batch_size):\n            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)\n            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)\n            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # Multi-label output\n            \n            xs.mark_sharding(input_ids, mesh, (0, 1))\n            xs.mark_sharding(attention_mask, mesh, (0, 1))\n            xs.mark_sharding(labels, mesh, (0, 1))\n            \n            yield input_ids, attention_mask, labels\n\nTRAIN_DATASET = train_dataset(CFG.BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:54:43.699717Z","iopub.execute_input":"2024-07-03T20:54:43.700012Z","iopub.status.idle":"2024-07-03T20:54:43.706777Z","shell.execute_reply.started":"2024-07-03T20:54:43.699955Z","shell.execute_reply":"2024-07-03T20:54:43.706016Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"# Load model for classification with 3 target label\nbase_model = LlamaForSequenceClassification.from_pretrained(\n    CFG.MODEL_NAME,\n    num_labels=CFG.NUM_LABELS,\n    torch_dtype=torch.bfloat16)\n\nbase_model.config.pretraining_tp = 1 \n\n# Assign Padding TOKEN\nbase_model.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:54:43.707649Z","iopub.execute_input":"2024-07-03T20:54:43.707884Z","iopub.status.idle":"2024-07-03T20:56:31.013306Z","shell.execute_reply.started":"2024-07-03T20:54:43.707859Z","shell.execute_reply":"2024-07-03T20:56:31.012456Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.13s/it]\nSome weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/llama-3/transformers/8b-chat-hf/1 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Low-Rank Adaptation [LORA]","metadata":{}},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=CFG.LORA_RANK,  # the dimension of the low-rank matrices\n    lora_alpha = CFG.LORA_ALPHA, # scaling factor for LoRA activations vs pre-trained weight activations\n    lora_dropout= CFG.DROPOUT, \n    bias='none',\n    inference_mode=False,\n    task_type=TaskType.SEQ_CLS,\n    target_modules=CFG.LORA_MODULES ) # Only Use Output and Values Projection","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:31.015299Z","iopub.execute_input":"2024-07-03T20:56:31.015581Z","iopub.status.idle":"2024-07-03T20:56:31.019858Z","shell.execute_reply.started":"2024-07-03T20:56:31.015554Z","shell.execute_reply":"2024-07-03T20:56:31.019060Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Create LoRa Model\nmodel = get_peft_model(base_model, lora_config)\n# Trainable Parameters\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:31.020885Z","iopub.execute_input":"2024-07-03T20:56:31.021109Z","iopub.status.idle":"2024-07-03T20:56:31.112834Z","shell.execute_reply.started":"2024-07-03T20:56:31.021086Z","shell.execute_reply":"2024-07-03T20:56:31.112041Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"trainable params: 1,716,224 || all params: 7,506,653,184 || trainable%: 0.022862705361931905\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of TPU Nodes\nnum_devices = xr.global_runtime_device_count()\nmesh_shape = (1, num_devices, 1)\ndevice_ids = np.array(range(num_devices))\nmesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))\n# distribute model\npartition_module(model, mesh)\n\nprint(f'num_devices: {num_devices}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:31.113796Z","iopub.execute_input":"2024-07-03T20:56:31.114324Z","iopub.status.idle":"2024-07-03T20:56:51.986624Z","shell.execute_reply.started":"2024-07-03T20:56:31.114296Z","shell.execute_reply":"2024-07-03T20:56:51.985414Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1720040192.203263      13 common_lib.cc:822] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=local.\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:539\n","output_type":"stream"},{"name":"stdout","text":"num_devices: 8\n","output_type":"stream"}]},{"cell_type":"code","source":"# Verfy The Trainable Layers\nMODEL_LAYERS_ROWS = []\nTRAINABLE_PARAMS = []\nN_TRAINABLE_PARAMS = 0\n\nfor name, param in model.named_parameters():\n    # Layer Parameter Count\n    n_parameters = int(torch.prod(torch.tensor(param.shape)))\n    # Only Trainable Layers\n    if param.requires_grad:\n        # Add Layer Information\n        MODEL_LAYERS_ROWS.append({\n            'param': n_parameters,\n            'name': name,\n            'dtype': param.data.dtype,\n        })\n        # Append Trainable Parameter\n        TRAINABLE_PARAMS.append({ 'params': param })\n        # Add Number Of Trainable Parameters\"\n        N_TRAINABLE_PARAMS += n_parameters\n        \ndisplay(pd.DataFrame(MODEL_LAYERS_ROWS))\n\nprint(f\"\"\"\n===============================\nN_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}\nN_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}\n===============================\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:51.987711Z","iopub.execute_input":"2024-07-03T20:56:51.987973Z","iopub.status.idle":"2024-07-03T20:56:52.011701Z","shell.execute_reply.started":"2024-07-03T20:56:51.987945Z","shell.execute_reply":"2024-07-03T20:56:52.010771Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"     param                                               name           dtype\n0    16384  base_model.model.model.layers.0.self_attn.v_pr...   torch.float32\n1     4096  base_model.model.model.layers.0.self_attn.v_pr...   torch.float32\n2    16384  base_model.model.model.layers.0.self_attn.o_pr...   torch.float32\n3    16384  base_model.model.model.layers.0.self_attn.o_pr...   torch.float32\n4    16384  base_model.model.model.layers.1.self_attn.v_pr...   torch.float32\n..     ...                                                ...             ...\n124  16384  base_model.model.model.layers.31.self_attn.v_p...   torch.float32\n125   4096  base_model.model.model.layers.31.self_attn.v_p...   torch.float32\n126  16384  base_model.model.model.layers.31.self_attn.o_p...   torch.float32\n127  16384  base_model.model.model.layers.31.self_attn.o_p...   torch.float32\n128  12288  base_model.model.score.modules_to_save.default...  torch.bfloat16\n\n[129 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param</th>\n      <th>name</th>\n      <th>dtype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16384</td>\n      <td>base_model.model.model.layers.0.self_attn.v_pr...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4096</td>\n      <td>base_model.model.model.layers.0.self_attn.v_pr...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16384</td>\n      <td>base_model.model.model.layers.0.self_attn.o_pr...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16384</td>\n      <td>base_model.model.model.layers.0.self_attn.o_pr...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16384</td>\n      <td>base_model.model.model.layers.1.self_attn.v_pr...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>16384</td>\n      <td>base_model.model.model.layers.31.self_attn.v_p...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>4096</td>\n      <td>base_model.model.model.layers.31.self_attn.v_p...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>16384</td>\n      <td>base_model.model.model.layers.31.self_attn.o_p...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>16384</td>\n      <td>base_model.model.model.layers.31.self_attn.o_p...</td>\n      <td>torch.float32</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>12288</td>\n      <td>base_model.model.score.modules_to_save.default...</td>\n      <td>torch.bfloat16</td>\n    </tr>\n  </tbody>\n</table>\n<p>129 rows × 3 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n===============================\nN_TRAINABLE_PARAMS: 1,716,224\nN_TRAINABLE_LAYERS: 129\n===============================\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# LR & Optimizer\nN_SAMPLES = len(train)\nSTEPS_PER_EPOCH = N_SAMPLES // CFG.BATCH_SIZE\n\nOPTIMIZER = torch.optim.AdamW(model.parameters(), lr=CFG.LR_MAX)\n\n# Cosine Learning Rate With Warmup\nlr_scheduler = transformers.get_cosine_schedule_with_warmup(\n    optimizer=OPTIMIZER,\n    num_warmup_steps=CFG.NUM_WARMUP_STEPS,\n    num_training_steps=STEPS_PER_EPOCH * CFG.NUM_EPOCHS)\n\nprint(f'BATCH_SIZE: {CFG.BATCH_SIZE}, N_SAMPLES: {N_SAMPLES}, STEPS_PER_EPOCH: {STEPS_PER_EPOCH}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:52.012803Z","iopub.execute_input":"2024-07-03T20:56:52.013024Z","iopub.status.idle":"2024-07-03T20:56:52.021391Z","shell.execute_reply.started":"2024-07-03T20:56:52.013000Z","shell.execute_reply":"2024-07-03T20:56:52.020487Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"BATCH_SIZE: 8, N_SAMPLES: 28729, STEPS_PER_EPOCH: 3591\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the data type for the optimizer's state (e.g., momentum buffers)\nfor state in OPTIMIZER.state.values():\n    for k, v in state.items():\n        if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:\n            state[v] = v.to(dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:52.022493Z","iopub.execute_input":"2024-07-03T20:56:52.022793Z","iopub.status.idle":"2024-07-03T20:56:52.038168Z","shell.execute_reply.started":"2024-07-03T20:56:52.022770Z","shell.execute_reply":"2024-07-03T20:56:52.037418Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"input_ids, attention_mask, labels = next(TRAIN_DATASET)\n\nprint(f'input_ids shape: {input_ids.shape}, dtype: {input_ids.dtype}')\nprint(f'attention_mask shape: {attention_mask.shape}, dtype: {attention_mask.dtype}')\nprint(f'labels shape: {labels.shape}, dtype: {labels.dtype}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:52.040263Z","iopub.execute_input":"2024-07-03T20:56:52.040674Z","iopub.status.idle":"2024-07-03T20:56:52.055533Z","shell.execute_reply.started":"2024-07-03T20:56:52.040644Z","shell.execute_reply":"2024-07-03T20:56:52.054627Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"input_ids shape: torch.Size([8, 1080]), dtype: torch.int64\nattention_mask shape: torch.Size([8, 1080]), dtype: torch.int64\nlabels shape: torch.Size([8, 3]), dtype: torch.int64\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n# Dummy Prediction\nwith torch.no_grad():\n    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n    \nprint(f'logits: {outputs.logits}, dtype: {outputs.logits.dtype}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:56:52.056471Z","iopub.execute_input":"2024-07-03T20:56:52.056725Z","iopub.status.idle":"2024-07-03T20:57:27.873122Z","shell.execute_reply.started":"2024-07-03T20:56:52.056702Z","shell.execute_reply":"2024-07-03T20:57:27.872098Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"logits: tensor([[ 0.1914,  3.0469,  4.4062],\n        [ 1.1406,  0.7578,  0.9844],\n        [ 2.1406,  2.0156,  5.5625],\n        [ 0.0801,  2.7031,  1.9062],\n        [ 1.3125,  2.2969,  3.1094],\n        [-2.8750,  2.3594,  3.0469],\n        [-1.9531, -0.6562,  2.7500],\n        [ 2.7344,  0.3750, -2.1562]], device='xla:0', dtype=torch.bfloat16), dtype: torch.bfloat16\nCPU times: user 1min 40s, sys: 15.6 s, total: 1min 55s\nWall time: 35.8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Put Model In Train Mode\nmodel.train()\n\n# Loss Function, Cross Entropy\nLOSS_FN = torch.nn.CrossEntropyLoss().to(dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T20:57:27.874428Z","iopub.execute_input":"2024-07-03T20:57:27.874723Z","iopub.status.idle":"2024-07-03T20:57:27.883166Z","shell.execute_reply.started":"2024-07-03T20:57:27.874691Z","shell.execute_reply":"2024-07-03T20:57:27.882391Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"st = time()\nwarnings.filterwarnings(\"error\")\nMETRICS = {\n    'loss': [],\n    'accuracy': {'y_true': [], 'y_pred': [] }}\n\nfor epoch in tqdm(range(CFG.NUM_EPOCHS)):\n    ste = time()\n    for step in range(STEPS_PER_EPOCH):\n        # Zero Out Gradients\n        OPTIMIZER.zero_grad()\n        \n        # Get Batch\n        input_ids, attention_mask, labels = next(TRAIN_DATASET)\n        \n        # Forward Pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n       \n        # Logits Float32\n        logits = outputs.logits.to(dtype=torch.float32)\n        \n        # Backward Pass\n        loss = LOSS_FN(logits, labels.to(dtype=torch.float32))\n        loss.backward()\n        \n        # optimizer step\n        OPTIMIZER.step()\n        xm.mark_step()\n        \n        # Update Learning Rate Scheduler\n        lr_scheduler.step()\n        \n        # Update Metrics And Progress Bar\n        METRICS['loss'].append(float(loss))\n        METRICS['accuracy']['y_true'] += labels.squeeze().tolist()\n        METRICS['accuracy']['y_pred'] += torch.argmax(F.softmax(logits, dim=-1), dim=1).cpu().tolist()\n        \n        if (step + 1) % 200 == 0:  \n            metrics = 'µ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n            metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])\n            metrics += ', µ_auc: {:.3f}'.format(accuracy_score(torch.argmax(torch.tensor(METRICS['accuracy']['y_true']), axis=-1), \\\n                                                               METRICS['accuracy']['y_pred']))\n            lr = OPTIMIZER.param_groups[0]['lr']\n            print(f'{epoch+1:02}/{CFG.NUM_EPOCHS:02} | {step+1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}', end='')\n            print(f'\\nSteps per epoch: {step+1} complete | Time elapsed: {time()- st}')\n    \n    print(f'\\nEpoch {epoch+1} Completed | Total time for epoch: {time() - ste} ' )\n\n    # If stopped, and to continue training in future on tpu we save model and optimizer\n    xm.save({k: v.cpu() for k, v in model.named_parameters() if v.requires_grad}, f'model_llama_3_cp_{epoch+1}_v1.pth')\n    xm.save(OPTIMIZER.state_dict(), f'optimizer_llama_3_cp_{epoch+1}_v1.pth')    \n    \n    print(f'Model saved at epoch {epoch+1}| Elapsed time: {time() - st} ')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nplt.plot(METRICS['loss'])    \nplt.xlabel('Step per epoch')\nplt.ylabel('Loss')\nplt.title('Loss Plot step per epoch')    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T21:25:04.756317Z","iopub.status.idle":"2024-07-03T21:25:04.756603Z","shell.execute_reply.started":"2024-07-03T21:25:04.756462Z","shell.execute_reply":"2024-07-03T21:25:04.756477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.cpu()\ntorch.save(dict([(k,v) for k, v in model.named_parameters() if v.requires_grad]), 'llama_3_finetuned_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T21:25:04.757431Z","iopub.status.idle":"2024-07-03T21:25:04.757761Z","shell.execute_reply.started":"2024-07-03T21:25:04.757601Z","shell.execute_reply":"2024-07-03T21:25:04.757617Z"},"trusted":true},"execution_count":null,"outputs":[]}]}